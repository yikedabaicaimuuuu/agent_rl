#
# This file is autogenerated by pip-compile with Python 3.11
# by the following command:
#
#    pip-compile requirements.in
#
aiohappyeyeballs==2.6.1
    # via aiohttp
aiohttp==3.11.18
    # via
    #   fsspec
    #   langchain-community
    #   litellm
aiosignal==1.3.2
    # via aiohttp
alembic==1.15.2
    # via
    #   -r requirements.in
    #   optuna
annotated-types==0.7.0
    # via pydantic
anyio==4.9.0
    # via
    #   asyncer
    #   dspy
    #   httpx
    #   openai
    #   sse-starlette
    #   starlette
appdirs==1.4.4
    # via ragas
asyncer==0.0.8
    # via dspy
attrs==25.3.0
    # via
    #   aiohttp
    #   jsonschema
    #   referencing
backoff==2.2.1
    # via dspy
cachetools==5.5.2
    # via dspy
certifi==2025.4.26
    # via
    #   httpcore
    #   httpx
    #   requests
charset-normalizer==3.4.2
    # via requests
click==8.2.1
    # via
    #   litellm
    #   uvicorn
cloudpickle==3.1.1
    # via dspy
colorlog==6.9.0
    # via optuna
dataclasses-json==0.6.7
    # via langchain-community
datasets==3.6.0
    # via
    #   -r requirements.in
    #   dspy
    #   ragas
dill==0.3.8
    # via
    #   datasets
    #   multiprocess
diskcache==5.6.3
    # via
    #   -r requirements.in
    #   dspy
    #   ragas
distro==1.9.0
    # via openai
dspy==2.6.24
    # via -r requirements.in
faiss-cpu==1.7.4
    # via -r requirements.in
fastapi==0.115.14
    # via -r requirements.in
filelock==3.18.0
    # via
    #   datasets
    #   huggingface-hub
    #   torch
frozenlist==1.6.0
    # via
    #   aiohttp
    #   aiosignal
fsspec[http]==2025.3.0
    # via
    #   datasets
    #   huggingface-hub
    #   torch
greenlet==3.2.2
    # via sqlalchemy
h11==0.16.0
    # via
    #   httpcore
    #   uvicorn
httpcore==1.0.9
    # via httpx
httpx==0.28.1
    # via
    #   langgraph-sdk
    #   langsmith
    #   litellm
    #   openai
httpx-sse==0.4.0
    # via langchain-community
huggingface-hub==0.31.2
    # via
    #   -r requirements.in
    #   datasets
    #   tokenizers
idna==3.10
    # via
    #   anyio
    #   httpx
    #   requests
    #   yarl
importlib-metadata==8.7.0
    # via litellm
jinja2==3.1.6
    # via
    #   litellm
    #   torch
jiter==0.9.0
    # via openai
joblib==1.5.0
    # via dspy
json-repair==0.45.0
    # via dspy
jsonpatch==1.33
    # via langchain-core
jsonpointer==3.0.0
    # via jsonpatch
jsonschema==4.23.0
    # via litellm
jsonschema-specifications==2025.4.1
    # via jsonschema
langchain==0.3.25
    # via
    #   -r requirements.in
    #   langchain-community
    #   ragas
langchain-community==0.3.24
    # via
    #   -r requirements.in
    #   ragas
langchain-core==0.3.60
    # via
    #   -r requirements.in
    #   langchain
    #   langchain-community
    #   langchain-openai
    #   langchain-text-splitters
    #   langgraph
    #   langgraph-checkpoint
    #   langgraph-prebuilt
    #   ragas
langchain-openai==0.3.17
    # via
    #   -r requirements.in
    #   ragas
langchain-text-splitters==0.3.8
    # via
    #   -r requirements.in
    #   langchain
langgraph==0.4.5
    # via -r requirements.in
langgraph-checkpoint==2.0.26
    # via
    #   -r requirements.in
    #   langgraph
    #   langgraph-prebuilt
langgraph-prebuilt==0.1.8
    # via
    #   -r requirements.in
    #   langgraph
langgraph-sdk==0.1.69
    # via
    #   -r requirements.in
    #   langgraph
langsmith==0.3.42
    # via
    #   -r requirements.in
    #   langchain
    #   langchain-community
    #   langchain-core
litellm==1.70.0
    # via
    #   -r requirements.in
    #   dspy
magicattr==0.1.6
    # via dspy
mako==1.3.10
    # via alembic
markdown-it-py==3.0.0
    # via rich
markupsafe==3.0.2
    # via
    #   jinja2
    #   mako
marshmallow==3.26.1
    # via dataclasses-json
mdurl==0.1.2
    # via markdown-it-py
mpmath==1.3.0
    # via sympy
multidict==6.4.3
    # via
    #   aiohttp
    #   yarl
multiprocess==0.70.16
    # via datasets
mypy-extensions==1.1.0
    # via typing-inspect
nest-asyncio==1.6.0
    # via ragas
networkx==3.6.1
    # via torch
numpy==1.26.4
    # via
    #   -r requirements.in
    #   datasets
    #   dspy
    #   langchain-community
    #   optuna
    #   pandas
    #   ragas
    #   torchvision
openai==1.75.0
    # via
    #   -r requirements.in
    #   dspy
    #   langchain-openai
    #   litellm
    #   ragas
optuna==4.3.0
    # via
    #   -r requirements.in
    #   dspy
orjson==3.10.18
    # via
    #   -r requirements.in
    #   langgraph-sdk
    #   langsmith
ormsgpack==1.9.1
    # via langgraph-checkpoint
packaging==24.2
    # via
    #   datasets
    #   huggingface-hub
    #   langchain-core
    #   langsmith
    #   marshmallow
    #   optuna
pandas==2.2.3
    # via
    #   -r requirements.in
    #   datasets
    #   dspy
pillow==12.0.0
    # via torchvision
propcache==0.3.1
    # via
    #   aiohttp
    #   yarl
pyarrow==20.0.0
    # via
    #   -r requirements.in
    #   datasets
pydantic==2.11.4
    # via
    #   -r requirements.in
    #   dspy
    #   fastapi
    #   langchain
    #   langchain-core
    #   langgraph
    #   langsmith
    #   litellm
    #   openai
    #   pydantic-settings
    #   ragas
pydantic-core==2.33.2
    # via pydantic
pydantic-settings==2.9.1
    # via
    #   -r requirements.in
    #   langchain-community
pygments==2.19.1
    # via rich
python-dateutil==2.9.0.post0
    # via pandas
python-dotenv==1.1.0
    # via
    #   -r requirements.in
    #   litellm
    #   pydantic-settings
pytz==2025.2
    # via pandas
pyyaml==6.0.2
    # via
    #   datasets
    #   huggingface-hub
    #   langchain
    #   langchain-community
    #   langchain-core
    #   optuna
ragas==0.2.15
    # via -r requirements.in
referencing==0.36.2
    # via
    #   jsonschema
    #   jsonschema-specifications
regex==2024.11.6
    # via
    #   dspy
    #   tiktoken
requests==2.32.3
    # via
    #   -r requirements.in
    #   datasets
    #   dspy
    #   huggingface-hub
    #   langchain
    #   langchain-community
    #   langsmith
    #   requests-toolbelt
    #   tiktoken
requests-toolbelt==1.0.0
    # via langsmith
rich==14.0.0
    # via
    #   -r requirements.in
    #   dspy
rpds-py==0.25.0
    # via
    #   jsonschema
    #   referencing
six==1.17.0
    # via python-dateutil
sniffio==1.3.1
    # via
    #   anyio
    #   openai
sqlalchemy==2.0.41
    # via
    #   -r requirements.in
    #   alembic
    #   langchain
    #   langchain-community
    #   optuna
sse-starlette==2.3.6
    # via -r requirements.in
starlette==0.46.2
    # via
    #   fastapi
    #   starlette-context
starlette-context==0.3.6
    # via -r requirements.in
sympy==1.14.0
    # via torch
tenacity==9.1.2
    # via
    #   dspy
    #   langchain-community
    #   langchain-core
tiktoken==0.9.0
    # via
    #   -r requirements.in
    #   langchain-openai
    #   litellm
    #   ragas
tokenizers==0.21.1
    # via litellm
torch==2.2.2
    # via
    #   -r requirements.in
    #   torchaudio
    #   torchvision
torchaudio==2.2.2
    # via -r requirements.in
torchvision==0.17.2
    # via -r requirements.in
tqdm==4.67.1
    # via
    #   datasets
    #   dspy
    #   huggingface-hub
    #   openai
    #   optuna
typing-extensions==4.13.2
    # via
    #   alembic
    #   anyio
    #   fastapi
    #   huggingface-hub
    #   langchain-core
    #   openai
    #   pydantic
    #   pydantic-core
    #   referencing
    #   sqlalchemy
    #   torch
    #   typing-inspect
    #   typing-inspection
typing-inspect==0.9.0
    # via dataclasses-json
typing-inspection==0.4.0
    # via
    #   pydantic
    #   pydantic-settings
tzdata==2025.2
    # via pandas
ujson==5.10.0
    # via
    #   -r requirements.in
    #   dspy
urllib3==2.4.0
    # via requests
uvicorn==0.35.0
    # via -r requirements.in
xxhash==3.5.0
    # via
    #   datasets
    #   langgraph
yarl==1.20.0
    # via aiohttp
zipp==3.21.0
    # via importlib-metadata
zstandard==0.23.0
    # via langsmith
#
# --- Hybrid retrieval & reranking (added manually) ---
#
rank-bm25>=0.2.2
    # via agents.hybrid_retriever (BM25 sparse retrieval)
sentence-transformers>=2.2.0
    # via agents.reranker (cross-encoder reranking)
