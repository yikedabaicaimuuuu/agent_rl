# agents/retrieval_agent.py
import time
from typing import Optional, Dict, Any, List, Callable, Tuple, Union

try:
    from langchain.schema import Document as LC_Document
except Exception:
    LC_Document = None

from utils.trajectory_logger import TrajectoryLogger


Number = Union[int, float]


def _to_float_safe(x: Any) -> Optional[float]:
    try:
        # å…¼å®¹ "0.42" / numpy æ ‡é‡
        return float(x)
    except Exception:
        return None


class RetrievalAgent:
    def __init__(
        self,
        vectorstore,
        evaluation_agent,
        top_k: int = 5,
        logger: Optional[TrajectoryLogger] = None,
        reranker: Optional[Callable[[List], List]] = None,
        dedupe: bool = True,
        min_score: Optional[float] = None,   # ğŸ”¹å¯é€‰ï¼šè¿‡æ»¤ä½åˆ†å‘½ä¸­
        obs_snippet_len: int = 200,          # ğŸ”¹è®°å½•åˆ° logger çš„æ‘˜è¦é•¿åº¦
        hybrid_retriever=None,               # ğŸ”¹HybridRetriever å®ä¾‹
        multi_query_fn: Optional[Callable] = None,  # ğŸ”¹query -> [query_variants]
    ):
        """
        Args:
            vectorstore: LangChain VectorStoreï¼ˆå·²å»ºå¥½ç´¢å¼•ï¼‰
            evaluation_agent: ä½ çš„è¯„ä¼°å™¨ï¼Œéœ€æä¾› evaluate_retrieval()
            top_k: é»˜è®¤ Top-K
            logger: è½¨è¿¹è®°å½•å™¨ï¼ˆå¯ä¸ºç©ºï¼‰
            reranker: å¯é€‰é‡æ’å‡½æ•°ï¼šdocs -> docsï¼ˆåŒç±»å‹åˆ—è¡¨ï¼‰
            dedupe: æ˜¯å¦æŒ‰æ–‡æ¡£ id å»é‡
            min_score: è‹¥æä¾›ï¼Œåˆ™è¿‡æ»¤ score < min_score çš„æ–‡æ¡£ï¼ˆåŸºäº metadata/attrï¼‰
            obs_snippet_len: å†™å…¥æ—¥å¿—çš„ç‰‡æ®µé•¿åº¦ä¸Šé™
        """
        self.vectorstore = vectorstore
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": top_k})
        self.evaluation_agent = evaluation_agent
        self.top_k = top_k
        self.logger = logger
        self.reranker = reranker
        self.dedupe = dedupe
        self.min_score = min_score
        self.obs_snippet_len = max(0, int(obs_snippet_len))
        self.hybrid_retriever = hybrid_retriever
        self.multi_query_fn = multi_query_fn

    # ---- æ–‡æœ¬ / å…ƒä¿¡æ¯æŠ½å– ----
    def _doc_text(self, d) -> str:
        if d is None:
            return ""
        txt = getattr(d, "page_content", None)
        if isinstance(txt, str):
            return txt
        if isinstance(d, dict):
            v = d.get("page_content") or d.get("text") or d.get("content")
            if isinstance(v, str):
                return v
        if isinstance(d, str):
            return d
        return ""

    def _doc_meta(self, d) -> Dict[str, Any]:
        if d is None:
            return {}
        m = getattr(d, "metadata", None)
        if isinstance(m, dict):
            return m
        if isinstance(d, dict):
            v = d.get("metadata") or {}
            if isinstance(v, dict):
                return v
        return {}

    # ---- æ ‡å‡†åŒ–è¾“å…¥ç»“æ„ ----
    def _normalize_docs(self, raw) -> List:
        """
        æ¥å—ï¼š
          - List[Document] / List[dict] / List[str]
          - dict: {"documents": [... or list[list]], "metadatas": [...]}
          - tuple: (dict_like, extra) æˆ– (list_like, extra)
        è¿”å›ï¼š
          - List[Document é£æ ¼å¯¹è±¡]
        """
        # tuple: å–ç¬¬ä¸€ä¸ª
        if isinstance(raw, tuple) and raw:
            raw = raw[0]

        docs: List = []
        if raw is None:
            return docs

        # dict ç»“æ„
        if isinstance(raw, dict):
            if "documents" in raw:
                maybe_docs = raw.get("documents") or []
                maybe_metas = raw.get("metadatas") or []
                # å±•å¹³äºŒç»´ï¼šéƒ¨åˆ† retriever æ‰¹é‡è¿”å› list[list[str]]
                if maybe_docs and isinstance(maybe_docs[0], list):
                    flat_docs: List = []
                    flat_metas: List = []
                    for i, row in enumerate(maybe_docs):
                        # å¯¹åº”çš„ metas è¡Œ
                        metas_row = maybe_metas[i] if (isinstance(maybe_metas, list) and i < len(maybe_metas)) else []
                        # æ‹‰å¹³
                        for j, content in enumerate(row):
                            m = metas_row[j] if (isinstance(metas_row, list) and j < len(metas_row) and isinstance(metas_row[j], dict)) else {}
                            flat_docs.append(content)
                            flat_metas.append(m)
                    maybe_docs, maybe_metas = flat_docs, flat_metas

                # ä¸€ç»´å¯¹é½
                for i, content in enumerate(maybe_docs):
                    meta = {}
                    if isinstance(maybe_metas, list) and i < len(maybe_metas) and isinstance(maybe_metas[i], dict):
                        meta = maybe_metas[i]
                    text = self._doc_text(content)
                    if LC_Document is not None:
                        docs.append(LC_Document(page_content=text, metadata=meta))
                    else:
                        docs.append({"page_content": text, "metadata": meta})
                return docs

            # å…¶ä»–å¸¸è§é”®ï¼š{"docs": [...]} / {"results": [...]}
            maybe = raw.get("docs") or raw.get("results")
            if isinstance(maybe, list):
                raw = maybe  # ç»§ç»­ list åˆ†æ”¯

        # list ç»“æ„
        if isinstance(raw, list):
            for item in raw:
                if LC_Document is not None and hasattr(item, "page_content"):
                    docs.append(item)  # å·²æ˜¯ LC_Document
                elif isinstance(item, dict) and ("page_content" in item or "text" in item or "content" in item):
                    docs.append({"page_content": self._doc_text(item), "metadata": self._doc_meta(item)})
                elif isinstance(item, str):
                    if LC_Document is not None:
                        docs.append(LC_Document(page_content=item, metadata={}))
                    else:
                        docs.append({"page_content": item, "metadata": {}})
                else:
                    # å…œåº•æŠ½æ–‡æœ¬
                    txt = self._doc_text(item)
                    if txt:
                        if LC_Document is not None:
                            docs.append(LC_Document(page_content=txt, metadata={}))
                        else:
                            docs.append({"page_content": txt, "metadata": {}})
            return docs

        # å…¶ä»–ç±»å‹ï¼ˆå•ä¸ªå¯¹è±¡ï¼‰
        txt = self._doc_text(raw)
        if txt:
            if LC_Document is not None:
                docs.append(LC_Document(page_content=txt, metadata={}))
            else:
                docs.append({"page_content": txt, "metadata": {}})
        return docs

    # ---- ç»Ÿä¸€ doc id ----
    def _doc_id_of(self, d) -> str:
        meta = getattr(d, "metadata", {}) or {}
        # å¸¸è§ id å­—æ®µ
        for key in ("id", "_id", "doc_id"):
            if key in meta and meta[key]:
                return str(meta[key])
        from hashlib import sha256
        pc = (getattr(d, "page_content", "") or "")
        base = pc[:256] if pc else repr(meta)[:256]
        return sha256(base.encode("utf-8")).hexdigest()[:16]

    # ---- å‘½ä¸­æ‘˜è¦ ----
    def _hits_meta(self, docs: List) -> List[Dict[str, Any]]:
        hits = []
        for d in docs:
            doc_id = self._doc_id_of(d)
            score = None
            meta = getattr(d, "metadata", {}) or {}
            if "score" in meta:
                score = _to_float_safe(meta["score"])
            elif hasattr(d, "score"):
                score = _to_float_safe(getattr(d, "score"))
            hits.append({"doc_id": doc_id, "score": score})
        return hits

    # ---- å»é‡ï¼ˆå¯é€‰ï¼šä¿ç•™é«˜åˆ†ï¼‰ ----
    def _dedupe_docs(self, docs: List) -> List:
        if not self.dedupe:
            return docs
        seen: Dict[str, Any] = {}
        for d in docs:
            did = self._doc_id_of(d)
            cur_score = None
            meta = getattr(d, "metadata", {}) or {}
            if "score" in meta:
                cur_score = _to_float_safe(meta["score"])
            elif hasattr(d, "score"):
                cur_score = _to_float_safe(getattr(d, "score"))
            if did not in seen:
                seen[did] = (d, cur_score)
            else:
                # è‹¥æœ‰åˆ†æ•°åˆ™ä¿ç•™åˆ†æ•°æ›´é«˜çš„
                _, old_score = seen[did]
                if (cur_score is not None) and (old_score is None or cur_score > old_score):
                    seen[did] = (d, cur_score)
        return [pair[0] for pair in seen.values()]

    # ---- è¿‡æ»¤ä½åˆ† ----
    def _filter_by_min_score(self, docs: List) -> List:
        if self.min_score is None:
            return docs
        out = []
        for d in docs:
            meta = getattr(d, "metadata", {}) or {}
            score = meta.get("score", getattr(d, "score", None))
            score_f = _to_float_safe(score)
            if score_f is None or score_f >= self.min_score:
                out.append(d)
        return out

    # ---- åŠ¨æ€ä¿®æ”¹ k ----
    def set_top_k(self, k: int):
        self.top_k = max(1, int(k))
        self.retriever = self.vectorstore.as_retriever(search_kwargs={"k": self.top_k})

    # ---- ä¸»æµç¨‹ ----
    def retrieve(self, query: str, reference: Optional[str] = None) -> Dict[str, Any]:
        """
        Single-round retrieval logic, controlled by the upper layer router whether to retry.
        Returns:
          {
            "docs": [...],
            "context_precision": float,
            "context_recall": float,
            "latency_ms": float,
            "hits_meta": [{"doc_id":..., "score":...}, ...],
          }
        """
        t0 = time.time()

        # 1) Build list of queries (multi-query expansion if configured)
        queries = [query]
        if self.multi_query_fn:
            try:
                queries = self.multi_query_fn(query)
            except Exception:
                queries = [query]

        # 2) Retrieve documents for each query variant, merge results
        try:
            all_docs = []
            for q in queries:
                if self.hybrid_retriever is not None:
                    # Hybrid BM25 + FAISS path
                    q_docs = self.hybrid_retriever.retrieve(q, k=self.top_k)
                    all_docs.extend(q_docs)
                else:
                    # Original FAISS-only path
                    try:
                        raw = self.retriever.invoke(q)
                    except Exception:
                        raw = self.retriever.get_relevant_documents(q)
                    all_docs.extend(self._normalize_docs(raw))
            docs = all_docs
        except Exception as e:
            if self.logger:
                self.logger.add_tool_call(type="retrieval_error", query=query, topk=self.top_k, error=str(e))
            return {
                "docs": [],
                "context_precision": 0.0,
                "context_recall": 0.0,
                "latency_ms": (time.time() - t0) * 1000.0,
                "hits_meta": []
            }

        # 3) å¯é€‰é‡æ’
        if self.reranker and docs:
            try:
                docs = self.reranker(query, docs)
            except TypeError:
                # Fallback: old-style reranker that takes only docs
                docs = self.reranker(docs)
            except Exception:
                pass

        # 4) å»é‡ + ä½åˆ†è¿‡æ»¤
        docs = self._dedupe_docs(docs or [])
        docs = self._filter_by_min_score(docs)

        latency_ms = (time.time() - t0) * 1000.0
        hits_meta = self._hits_meta(docs)

        # 5) è®°å½•è°ƒç”¨
        if self.logger:
            self.logger.add_tool_call(
                type="retrieval",
                query=query,
                topk=self.top_k,
                latency_ms=round(latency_ms, 2),
                hits=hits_meta
            )
            for d in docs[: self.top_k]:
                snippet = (self._doc_text(d) or "")[: self.obs_snippet_len]
                if snippet:
                    self.logger.add_observation(snippet, do_hash=True)

        if not docs:
            print("âš ï¸ No documents retrieved")
            return {
                "docs": [],
                "context_precision": 0.0,
                "context_recall": None,   # æ”¹ä¸º None
                "weak_recall": None,      # æ–°å¢
                "latency_ms": latency_ms,
                "hits_meta": hits_meta
            }

        # 6) è¯„ä¼°æ£€ç´¢æ•ˆæœï¼ˆctx-P / ctx-Rï¼‰
        eval_result = self.evaluation_agent.evaluate_retrieval(
            user_query=query,
            retrieved_docs=docs,
            reference=reference
        ) or {}

        def _get(ev: Dict[str, Any], *keys, default=None):
            for k in keys:
                if k in ev:
                    v = ev[k]
                    try:
                        return float(v[0] if isinstance(v, list) else v)
                    except Exception:
                        continue
            return default

        context_precision = _get(eval_result, "context_precision", "ctxP", default=0.0)
        context_recall    = _get(eval_result, "context_recall", "ctxR", default=None)  # å¯èƒ½ä¸º None
        weak_recall       = _get(eval_result, "weak_recall", default=None)             # æ–°å¢ï¼šå¼±å¬å›

        # å‹å¥½æ‰“å°ï¼šæœ‰çœŸ recall æ‰“çœŸ recallï¼›å¦åˆ™æ‰“å° weak_recallï¼›éƒ½æ²¡æœ‰å°±æ˜¾ç¤º "n/a"
        if context_recall is not None:
            print(f"ğŸ” [Retrieval] k={self.top_k}  latency={latency_ms:.1f}ms  "
                  f"Precision={context_precision:.2f}, Recall={context_recall:.2f}")
        elif weak_recall is not None:
            print(f"ğŸ” [Retrieval] k={self.top_k}  latency={latency_ms:.1f}ms  "
                  f"Precision={context_precision:.2f}, WeakRecall={weak_recall:.2f}")
        else:
            print(f"ğŸ” [Retrieval] k={self.top_k}  latency={latency_ms:.1f}ms  "
                  f"Precision={context_precision:.2f}, Recall=n/a")

        return {
            "docs": docs,
            "context_precision": float(context_precision or 0.0),
            "context_recall": context_recall,      # å¯èƒ½æ˜¯ None
            "weak_recall": weak_recall,            # å¯èƒ½æ˜¯ None
            "latency_ms": latency_ms,
            "hits_meta": hits_meta
        }
