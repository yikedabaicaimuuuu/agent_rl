import os
import json
from datasets import load_dataset
import pprint

def build_hotpot_mini(
    output_path="data-hotpot/hotpot_mini_corpus.json",
    num_questions=1000
):
    """ä» HotpotQA 'fullwiki' æ„å»ºå°è§„æ¨¡ 'context + question + answer' mini corpus"""

    # 1. åŠ è½½ HotpotQA fullwiki (åªå– 1% èŠ‚çœæ—¶é—´)
    print("ğŸš€ Loading small subset of HotpotQA...")
    dataset = load_dataset('hotpot_qa', 'fullwiki', split='train[:1%]')
    print(f"âœ… Loaded {len(dataset)} examples.")

    # è°ƒè¯•ï¼šæ£€æŸ¥æ•°æ®é›†ç»“æ„
    print("\nğŸ” Examining dataset structure...")
    example = dataset[0]
    print("Available keys:", list(example.keys()))

    # æ‰“å°ç¤ºä¾‹æ¡ç›®çš„å®Œæ•´ç»“æ„ä»¥ä¾¿ç†è§£
    print("\nSample data item structure:")
    for key in example.keys():
        print(f"{key}: {type(example[key])}")
        if key == 'context':
            print(f"  - Context type: {type(example[key])}")
            if isinstance(example[key], list) and len(example[key]) > 0:
                print(f"  - First context item: {example[key][0]}")
        elif key == 'supporting_facts':
            print(f"  - Supporting facts type: {type(example[key])}")
            if isinstance(example[key], dict):
                print(f"  - Supporting facts keys: {example[key].keys()}")
                for sf_key in example[key].keys():
                    print(f"    - {sf_key}: {type(example[key][sf_key])}")
                    if hasattr(example[key][sf_key], '__len__') and len(example[key][sf_key]) > 0:
                        print(f"      - First item: {example[key][sf_key][0]}")
            elif isinstance(example[key], list) and len(example[key]) > 0:
                print(f"  - First supporting fact: {example[key][0]}")

    # 2. æ‰“ä¹±å¹¶å–å‰ num_questions æ¡
    dataset = dataset.shuffle(seed=42).select(range(min(len(dataset), num_questions)))

    processed_examples = []

    print("\nğŸ” Processing examples...")
    for i, item in enumerate(dataset):
        if i % 20 == 0:
            print(f"Processing example {i}/{len(dataset)}...")

        question = item['question']
        answer = item['answer']

        context_texts = []

        try:
            # æ ¹æ®æ•°æ®å¡ç»“æ„ï¼Œcontextå¯èƒ½æœ‰ä¸åŒçš„æ ¼å¼
            if 'context' in item:
                contexts = item['context']

                # è°ƒè¯•ç¬¬ä¸€ä¸ªæ¡ç›®çš„ç»“æ„
                if i == 0:
                    print("\nFirst item context structure:")
                    print(f"Type: {type(contexts)}")
                    if isinstance(contexts, list) and len(contexts) > 0:
                        print(f"First element: {contexts[0]}")
                    elif isinstance(contexts, dict):
                        print(f"Context keys: {contexts.keys()}")
                        for context_key in contexts.keys():
                            if hasattr(contexts[context_key], '__len__') and len(contexts[context_key]) > 0:
                                print(f"First {context_key}: {contexts[context_key][0]}")

                # å¤„ç†æƒ…å†µ1: contextæ˜¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ æ˜¯[title, sentences]
                if isinstance(contexts, list):
                    for context_item in contexts:
                        if isinstance(context_item, list) and len(context_item) == 2:
                            title, sentences = context_item
                            if isinstance(sentences, list):
                                paragraph = f"{title}: " + " ".join([s if isinstance(s, str) else s[0] if isinstance(s, list) and len(s) > 0 else "" for s in sentences])
                                context_texts.append(paragraph)

                # å¤„ç†æƒ…å†µ2: contextæ˜¯å­—å…¸ï¼Œæœ‰'sentences'å’Œ'title'å­—æ®µ
                elif isinstance(contexts, dict) and 'sentences' in contexts and 'title' in contexts:
                    titles = contexts['title']
                    all_sentences = contexts['sentences']

                    # ç¡®ä¿æ ‡é¢˜å’Œå¥å­åˆ—è¡¨é•¿åº¦åŒ¹é…
                    if len(titles) == len(all_sentences):
                        for idx, (title, sentences) in enumerate(zip(titles, all_sentences)):
                            if sentences:
                                # å¤„ç†sentenceså¯èƒ½æ˜¯åµŒå¥—åˆ—è¡¨çš„æƒ…å†µ
                                sentence_texts = []
                                for sent in sentences:
                                    if isinstance(sent, str):
                                        sentence_texts.append(sent)
                                    elif isinstance(sent, list) and len(sent) > 0:
                                        sentence_texts.append(sent[0])

                                paragraph = f"{title}: " + " ".join(sentence_texts)
                                context_texts.append(paragraph)

            # å¦‚æœcontextå¤„ç†åä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨supporting_facts
            if not context_texts and 'supporting_facts' in item:
                supporting_facts = item['supporting_facts']

                # è°ƒè¯•supporting_factsç»“æ„
                if i == 0:
                    print("\nSupporting facts structure:")
                    print(f"Type: {type(supporting_facts)}")
                    if isinstance(supporting_facts, dict):
                        print(f"Keys: {supporting_facts.keys()}")
                        for sf_key in supporting_facts.keys():
                            if hasattr(supporting_facts[sf_key], '__len__') and len(supporting_facts[sf_key]) > 0:
                                print(f"First {sf_key}: {supporting_facts[sf_key][0]}")
                    elif isinstance(supporting_facts, list) and len(supporting_facts) > 0:
                        print(f"First item: {supporting_facts[0]}")

                # å¤„ç†supporting_factsä¸ºå­—å…¸çš„æƒ…å†µ
                if isinstance(supporting_facts, dict) and 'title' in supporting_facts:
                    titles = supporting_facts['title']
                    # å°è¯•ä»contextä¸­æ‰¾åˆ°å¯¹åº”çš„å†…å®¹
                    if isinstance(contexts, dict) and 'sentences' in contexts:
                        all_sentences = contexts['sentences']
                        for title in titles:
                            # åœ¨contextçš„titleä¸­æ‰¾åˆ°å¯¹åº”é¡¹
                            if title in contexts['title']:
                                idx = contexts['title'].index(title)
                                if idx < len(all_sentences) and all_sentences[idx]:
                                    paragraph = f"{title}: " + " ".join(all_sentences[idx])
                                    context_texts.append(paragraph)

                # å¤„ç†supporting_factsä¸ºåˆ—è¡¨çš„æƒ…å†µ
                elif isinstance(supporting_facts, list):
                    for fact in supporting_facts:
                        if isinstance(fact, list) and len(fact) >= 1:
                            title = fact[0]
                            # å°è¯•åœ¨contextsä¸­æ‰¾åˆ°å¯¹åº”å†…å®¹
                            for context_item in contexts if isinstance(contexts, list) else []:
                                if isinstance(context_item, list) and len(context_item) == 2 and context_item[0] == title:
                                    sentences = context_item[1]
                                    if sentences:
                                        paragraph = f"{title}: " + " ".join(sentences)
                                        context_texts.append(paragraph)
                                        break

        except Exception as e:
            print(f"Error processing item {i}: {e}")
            if i < 3:  # åªä¸ºå‰å‡ ä¸ªæ¡ç›®æä¾›æ›´è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯
                print(f"Question: {question}")
                try:
                    print(f"Context type: {type(item.get('context', 'No context'))}")
                    print(f"Supporting facts type: {type(item.get('supporting_facts', 'No supporting_facts'))}")
                except:
                    pass
            continue

        full_context = "\n\n".join(context_texts)

        if not full_context.strip():
            print(f"âš ï¸ Skipping item with empty context: {question}")
            # ä¸ºç©ºcontextçš„æ¡ç›®æä¾›æ›´è¯¦ç»†çš„è°ƒè¯•ä¿¡æ¯
            if i < 3:
                try:
                    if isinstance(item.get('context', {}), dict):
                        print(f"  - Context keys: {list(item['context'].keys())}")
                    else:
                        print(f"  - Context type: {type(item.get('context', 'Not found'))}")

                    if isinstance(item.get('supporting_facts', {}), dict):
                        print(f"  - Supporting facts keys: {list(item['supporting_facts'].keys())}")
                    else:
                        print(f"  - Supporting facts type: {type(item.get('supporting_facts', 'Not found'))}")
                except Exception as e:
                    print(f"  - Error printing debug info: {e}")
            continue

        # æ·»åŠ æˆåŠŸå¤„ç†çš„ç¤ºä¾‹
        processed_examples.append({
            "question": question,
            "answer": answer,
            "context": full_context
        })

        # æ‰“å°ç¬¬ä¸€ä¸ªæˆåŠŸå¤„ç†çš„ç¤ºä¾‹
        if len(processed_examples) == 1:
            print("\nâœ… First successful example:")
            print(f"Question: {question}")
            print(f"Answer: {answer}")
            print(f"Context (first 150 chars): {full_context[:150]}...")

    # 3. ä¿å­˜ä¸º JSON
    if processed_examples:
        os.makedirs(os.path.dirname(output_path), exist_ok=True)
        with open(output_path, 'w') as f:
            json.dump(processed_examples, f, indent=2, ensure_ascii=False)

        print(f"\nâœ… Saved {len(processed_examples)} examples to {output_path}")

        # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("\nğŸ“Š Statistics:")
        print(f"- Total processed examples: {len(processed_examples)}")
        avg_context_len = sum(len(ex['context']) for ex in processed_examples) / len(processed_examples)
        print(f"- Average context length: {avg_context_len:.1f} characters")
        print(f"- Sample questions: {processed_examples[0]['question'][:50]}...")
    else:
        print("\nâš ï¸ WARNING: No examples were processed! The output file is empty.")
        print("Please check the HotpotQA dataset structure and update the processing logic.")

if __name__ == "__main__":
    build_hotpot_mini()